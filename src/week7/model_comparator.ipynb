{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to compare Stijn's model and mine here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchbnn as bnn\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#allocating datasets and model to GPU for speed's sake\n",
    "is_available = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResulDualOutputBNN(nn.Module):\n",
    "    def __init__(self, no_of_neurones, dropout_prob):\n",
    "        super(ResulDualOutputBNN, self).__init__()\n",
    "        self.shared_layer = nn.Sequential( #this is the input layer\n",
    "            bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=2, out_features=no_of_neurones),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "        )\n",
    "\n",
    "        self.output_layer_y0 = nn.Sequential( #this is the output layer for y0\n",
    "            bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=no_of_neurones, out_features=no_of_neurones),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "            bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=no_of_neurones, out_features=1)\n",
    "        )\n",
    "        self.output_layer_y1 = nn.Sequential( #this is the output layer for y1\n",
    "            bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=no_of_neurones, out_features=no_of_neurones),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "            bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=no_of_neurones, out_features=1)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x): #this is the forward pass, run automatically when you call the model\n",
    "        shared = self.shared_layer(x)\n",
    "        y0 = self.output_layer_y0(shared)\n",
    "        y1 = self.output_layer_y1(shared)\n",
    "        return y0, y1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stijn's Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StijnDualOutputBNN(nn.Module):\n",
    "    def __init__(self, no_of_neurones, dropout_prob):\n",
    "        super(StijnDualOutputBNN, self).__init__()\n",
    "        self.shared_layer = nn.Sequential(\n",
    "        bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=2,\n",
    "                        out_features=no_of_neurones),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(dropout_prob),\n",
    "        bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=no_of_neurones,\n",
    "                        out_features=no_of_neurones),\n",
    "        )\n",
    "\n",
    "        self.output_layer_y0 = nn.Sequential(\n",
    "        bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=no_of_neurones,\n",
    "                        out_features=1),\n",
    "        )\n",
    "        self.output_layer_y1 = nn.Sequential(\n",
    "        bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=no_of_neurones,\n",
    "                        out_features=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        shared = self.shared_layer(x)\n",
    "        y0 = self.output_layer_y0(shared)\n",
    "        y1 = self.output_layer_y1(shared)\n",
    "        return y0, y1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each model, I'll:\n",
    "* Generate a dataset\n",
    "* Initialise the model\n",
    "* Train the model\n",
    "* Test the model\n",
    "* Find its MSE, residuals, and standard deviation\n",
    "* Plot it all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialising the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_model(model_name, no_of_neurones: int, dropout_prob: float, lr: float = 0.01) -> tuple:\n",
    "    \"\"\"\n",
    "    Initialise the DualOutputBNN model with its loss functions and optimizer.\n",
    "\n",
    "    Parameters:\n",
    "    - no_of_neurones (int): Number of neurons in the hidden layer.\n",
    "    - dropout_prob (float): Dropout probability.\n",
    "    - lr (float): Learning rate for the optimizer. Default is 0.01.\n",
    "\n",
    "    Returns:\n",
    "    - A tuple containing the initialized model, MSE loss function, KL loss function, KL weight, and optimizer.\n",
    "    \"\"\"\n",
    "\n",
    "    #make a model from ResulDualOutputBNN if model_name is 'Resul' and from StijnDualOutputBNN if model_name is 'Stijn'\n",
    "    match model_name.lower():\n",
    "        case 'resul':\n",
    "            model = ResulDualOutputBNN(no_of_neurones, dropout_prob).to(device)\n",
    "        case 'stijn':\n",
    "            model = StijnDualOutputBNN(no_of_neurones, dropout_prob).to(device)\n",
    "        case _:\n",
    "            raise ValueError(f\"Model name {model_name} is not valid. Please use either 'Resul' or 'Stijn'.\")\n",
    "\n",
    "    mse_loss = nn.MSELoss().to(device)\n",
    "    kl_loss = bnn.BKLLoss(reduction='mean', last_layer_only=False).to(device)\n",
    "    kl_weight = 0.01\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    return model.train(), mse_loss, kl_loss, kl_weight, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialising the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_dataset():\n",
    "    #forming initial dataset\n",
    "    x0, x1 = torch.rand(2000)*6 - 3, torch.rand(2000)*6 - 3\n",
    "    df = pd.DataFrame({'x0': x0, 'x1': x1})\n",
    "\n",
    "    #declaring target functions and their outputs\n",
    "    clean_f0 = lambda x0, x1: 4*np.power(x0, 5) + 12*np.power(x1, 3) - 5\n",
    "    clean_f1 = lambda x0, x1: 3*np.power(x0, 4) - 7*np.power(x1, 2) + 9*x0*x1\n",
    "\n",
    "    clean_y0, clean_y1 = clean_f0(x0, x1), clean_f1(x0, x1)\n",
    "\n",
    "    #declaring noisy functions and their outputs\n",
    "    max_y0_scale, max_y1_scale = clean_y0.max()*0.2, clean_y1.max()*0.2 #scale for noisy function\n",
    "    f0 = lambda x0, x1: clean_f0(x0, x1) + (max_y0_scale*torch.rand(x0.size()) - max_y0_scale/2)\n",
    "    f1 = lambda x0, x1: clean_f1(x0, x1) + (max_y1_scale*torch.rand(x0.size()) - max_y1_scale/2)\n",
    "\n",
    "    return df, f0, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(df: pd.DataFrame, func0, func1):\n",
    "    #splitting data into training and testing sets\n",
    "    x_train, x_test = train_test_split(df[[\"x0\", \"x1\"]], test_size=0.2, random_state=1)\n",
    "    x_train.reset_index(drop=True, inplace=True)\n",
    "    x_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    x_train = x_train.apply(lambda x: x.sort_values().values)\n",
    "    x_test = x_test.apply(lambda x: x.sort_values().values)\n",
    "    \n",
    "    #generating y values\n",
    "    y_train, y_test = pd.DataFrame(), pd.DataFrame()\n",
    "    y_train[\"y0\"], y_train[\"y1\"] = func0(torch.Tensor(x_train[\"x0\"]), torch.Tensor(x_train[\"x1\"])), func1(torch.Tensor(x_train[\"x0\"]), torch.Tensor(x_train[\"x1\"]))\n",
    "    y_test[\"y0\"], y_test[\"y1\"] = func0(torch.Tensor(x_test[\"x0\"]), torch.Tensor(x_test[\"x1\"])), func1(torch.Tensor(x_test[\"x0\"]), torch.Tensor(x_test[\"x1\"]))\n",
    "\n",
    "    #normalising dataset\n",
    "    normalise = lambda x: (x - np.mean(x)) / (np.std(x))\n",
    "    x_train[\"x0\"], x_train[\"x1\"] = normalise(x_train[\"x0\"]), normalise(x_train[\"x1\"])\n",
    "    x_test[\"x0\"], x_test[\"x1\"] = normalise(x_test[\"x0\"]), normalise(x_test[\"x1\"])\n",
    "\n",
    "    y_train[\"y0\"], y_train[\"y1\"] = normalise(y_train[\"y0\"]), normalise(y_train[\"y1\"])\n",
    "    y_test[\"y0\"], y_test[\"y1\"] = normalise(y_test[\"y0\"]), normalise(y_test[\"y1\"])\n",
    "\n",
    "    return torch.Tensor(np.array(x_train)), torch.Tensor(np.array(x_test)), torch.Tensor(np.array(y_train)), torch.Tensor(np.array(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_attributes, x_train, y_train, epochs: int, filename):\n",
    "    \"\"\"\n",
    "    Train a Bayesian Neural Network model for a specified number of epochs.\n",
    "\n",
    "    Parameters:\n",
    "    - model_attributes: A tuple containing the model, loss functions, kl_weight, and optimizer.\n",
    "    - x_train (torch.Tensor): Input tensor for the training data.\n",
    "    - y_train (torch.Tensor): Target tensor for the training data.\n",
    "    - epochs (int): Number of epochs to train the model.\n",
    "\n",
    "    Returns:\n",
    "    - model (torch.nn.Sequential): The trained neural network model.\n",
    "\n",
    "    Ensures that training data and model are on the same device for efficiency.\n",
    "    \"\"\"\n",
    "\n",
    "    model, mse_loss, kl_loss, kl_weight, optimizer = model_attributes\n",
    "    x_train, y_train = x_train.to(device), y_train.to(device)\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        y0_pred, y1_pred = model(x_train)\n",
    "        y0_mse, y1_mse = mse_loss(y0_pred, torch.unsqueeze(y_train[:,0], dim=1)), mse_loss(y1_pred, torch.unsqueeze(y_train[:,1], dim=1))\n",
    "        kl = kl_loss(model)\n",
    "        y0_cost, y1_cost = y0_mse + kl_weight * kl, y1_mse + kl_weight * kl\n",
    "        cost = y0_cost + y1_cost\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Cost: {cost.item():.3f}\")\n",
    "\n",
    "    x_train, y_train = x_train.cpu(), y_train.cpu()\n",
    "    return model.eval().cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, x_test):\n",
    "    \"\"\"\n",
    "    Test a Bayesian Neural Network model to produce predictions along with mean and standard deviation.\n",
    "\n",
    "    Parameters:\n",
    "    - model (torch.nn.Sequential): The trained neural network model.\n",
    "    - func (callable): The target function to compare against the model's predictions.\n",
    "\n",
    "    Returns:\n",
    "    - mean_model_results (numpy.ndarray): Array of mean predictions from the model.\n",
    "    - std_model_results (numpy.ndarray): Array of standard deviations of the predictions.\n",
    "    - x_test (torch.Tensor): Testing dataset inputs.\n",
    "    - y_test (torch.Tensor): Testing dataset targets.\n",
    "\n",
    "    The testing data is moved to the device specified by the global `device` variable.\n",
    "    \"\"\"\n",
    "\n",
    "    y0_pred, y1_pred = np.array([model(x_test)[0].detach().numpy() for _ in range(500)])[:,:,0].T, np.array([model(x_test)[1].detach().numpy() for _ in range(500)])[:,:,0].T\n",
    "\n",
    "    mean_y0_results, std_y0_results = np.array([np.mean(y0_pred[i]) for i in range(y0_pred.shape[0])]), np.array([np.std(y0_pred[i]) for i in range(y0_pred.shape[0])])\n",
    "    mean_y1_results, std_y1_results = np.array([np.mean(y1_pred[i]) for i in range(y1_pred.shape[0])]), np.array([np.std(y1_pred[i]) for i in range(y1_pred.shape[0])])\n",
    "\n",
    "    return mean_y0_results, std_y0_results, mean_y1_results, std_y1_results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Prediction Data\n",
    "\n",
    "This is basically a function where I combine all of the above, for a given model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prediction_data(model_name, data, filename):\n",
    "    x_train, x_test, y_train, y_test = data\n",
    "    df_test = pd.DataFrame({'x0': x_test[:,0], 'x1': x_test[:,1], 'y0': y_test[:,0], 'y1': y_test[:,1]}).reset_index(drop=True)\n",
    "    df_test.to_csv(f\"../../data/model_comparator/{filename}/data.csv\") \n",
    "\n",
    "    #where the machine learning occurs...\n",
    "    model_attributes = initialise_model(model_name, 1000, 0.3)\n",
    "    model = train_model(model_attributes, x_train, y_train, 1000, filename)\n",
    "    mean_y0_results, std_y0_results, mean_y1_results, std_y1_results = test_model(model, x_test)\n",
    "\n",
    "    mean_y0_mse, mean_y1_mse = model_attributes[1](torch.Tensor(mean_y0_results), y_test[:,0]), model_attributes[1](torch.Tensor(mean_y1_results), y_test[:,1])\n",
    "\n",
    "    print(f\"For {filename}'s model:\")\n",
    "    print(f\"mean_y0_mse: {mean_y0_mse}, mean_y1_mse: {mean_y1_mse}\")\n",
    "    print(f\"mean std(y0): {np.mean(std_y0_results)}, mean std(y1): {np.mean(std_y1_results)}\")\n",
    "\n",
    "    df_pred = pd.DataFrame({'x0': x_test[:,0], 'x1': x_test[:,1], 'y0': y_test[:,0], 'y1': y_test[:,1], 'mean_y0': mean_y0_results, 'mean_y1': mean_y1_results, 'std_y0': std_y0_results, 'std_y1': std_y1_results}).reset_index(drop=True)\n",
    "    return df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating dataset\n",
    "initial_df, func0, func1 = initialise_dataset()\n",
    "test_and_trains = generate_dataset(initial_df, func0, func1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 0.406\n",
      "For resul's model:\n",
      "mean_y0_mse: 0.16169138252735138, mean_y1_mse: 0.14625026285648346\n",
      "mean std(y0): 0.2000739723443985, mean std(y1): 0.21419867873191833\n"
     ]
    }
   ],
   "source": [
    "my_model_data = generate_prediction_data(\"resul\", test_and_trains, \"resul\")\n",
    "my_model_data.to_csv(\"../../data/model_comparator/resul/model_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 0.911\n",
      "For stijn's model:\n",
      "mean_y0_mse: 0.14515720307826996, mean_y1_mse: 0.12076136469841003\n",
      "mean std(y0): 0.790631890296936, mean std(y1): 0.7243708968162537\n"
     ]
    }
   ],
   "source": [
    "stijn_model_data = generate_prediction_data(\"stijn\", test_and_trains, \"stijn\")\n",
    "stijn_model_data.to_csv(\"../../data/model_comparator/stijn/model_predictions.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
