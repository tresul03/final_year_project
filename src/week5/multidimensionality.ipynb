{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to explore multi-dimensional inputs and outputs in this notebook.\n",
    "\n",
    "We're going to have $y = y(y_{0}, y_{1}, ..., y_{n})$, and $x = x(x_{0}, x_{1}, ..., x_{n})$. For simplicity's sake, let $n = 1$.\n",
    "\n",
    "I'm also going to assume each parameter of $x$ is mapped to its corresponding $y$ parameter: as in,\n",
    "\n",
    "$x_{0} \\rightarrow y_{0}$, and  $x_{1} \\rightarrow y_{1}$.\n",
    "\n",
    "There'll be functions mapping each input to its corresponding output, of course, for example,\n",
    "\n",
    "$y_{0} = x_{0}^{2}$, and $y_{1} = x_{1}^{4}$.\n",
    "\n",
    "I'm going to use more complex functions to strain the model a little more, but the real challenge is plotting these, because\n",
    "\n",
    "$x = [x_{0} \\; x_{1}]$, and $y = [y_{0} \\; y_{1}]$.\n",
    "\n",
    "A neural network usually has one output layer. I'm going to have to branch out the layer this time, such that each y-element has an output layer.\n",
    "\n",
    "Also, I'm going to use a dropout probability of 0.3, since, from the dropouts notebook, that seems to be the optimal choice.\n",
    "\n",
    "With that, I'll get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchbnn as bnn\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#allocating datasets and model to GPU for speed's sake\n",
    "is_available = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My data generation will be different here. I'm going to:\n",
    "* Have two linspaces: x0, x1\n",
    "* Have two  functions: fx0, fx1\n",
    "* Have two more linspaces: y0, y1\n",
    "* Form a dataframe (df) of the four linspaces\n",
    "* Use train_test_split on the df\n",
    "\n",
    "I'll think about device applications later.\n",
    "\n",
    "I'll also keep the functions simple:\n",
    "\n",
    "$y_{0} = f(x_{0}) = x^{5} -7x^{2} + 4$\n",
    "\n",
    "$y_{1} = f(x_{1}) = 3x^{2} + 2x - 5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.470471</td>\n",
       "      <td>-0.470471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.979980</td>\n",
       "      <td>1.979980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.931932</td>\n",
       "      <td>1.931932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.811812</td>\n",
       "      <td>-1.811812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.086086</td>\n",
       "      <td>0.086086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x0        x1\n",
       "0 -0.470471 -0.470471\n",
       "1  1.979980  1.979980\n",
       "2  1.931932  1.931932\n",
       "3 -1.811812 -1.811812\n",
       "4  0.086086  0.086086"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataset\n",
    "x0, x1 = torch.linspace(-2, 2, 1000), torch.linspace(-2, 2, 1000)\n",
    "\n",
    "fx0 = lambda x: np.power(x, 5) - 7*np.power(x, 2) + (torch.rand(x.size())*4 + 2)\n",
    "fx1 = lambda x: 3*np.power(x, 2) + 2*x - (torch.rand(x.shape)*5 + 2)\n",
    "\n",
    "y0 = fx0(x0)\n",
    "y1 = fx1(x1)\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"x0\":x0,\n",
    "        \"x1\":x1,\n",
    "        \"y0\":y0,\n",
    "        \"y1\":y0\n",
    "    }\n",
    ")\n",
    "\n",
    "#df.head()\n",
    "x_train, x_test, y_train, y_test = train_test_split(df[[\"x0\", \"x1\"]], df[[\"y0\", \"y1\"]], test_size=0.2, random_state=1)\n",
    "\n",
    "#reset indices and drop old indices of train and test sets\n",
    "x_train.reset_index(drop=True, inplace=True)\n",
    "x_test.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "y_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I'm working with multi-dimensional inputs and outputs, the model architecture has to change to accommodate the new dataset's properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualOutputBNN(nn.Module):\n",
    "    def __init__(self, no_of_neurones, dropout_prob):\n",
    "        super(DualOutputBNN, self).__init__()\n",
    "        self.shared_layer = nn.Sequential(\n",
    "            bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=2, out_features=no_of_neurones),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "        )\n",
    "        self.output_layer_y0 = bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=no_of_neurones, out_features=1)\n",
    "        self.output_layer_y1 = bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=no_of_neurones, out_features=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        shared = self.shared_layer(x)\n",
    "        y0 = self.output_layer_y0(shared)\n",
    "        y1 = self.output_layer_y1(shared)\n",
    "        return y0, y1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll now write a function to initialise the model above, in the same way that I did in previous notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_model(no_of_neurones: int, dropout_prob: float, lr: float = 0.01) -> tuple:\n",
    "    \"\"\"\n",
    "    Initialise the DualOutputBNN model with its loss functions and optimizer.\n",
    "\n",
    "    Parameters:\n",
    "    - no_of_neurones (int): Number of neurons in the hidden layer.\n",
    "    - dropout_prob (float): Dropout probability.\n",
    "    - lr (float): Learning rate for the optimizer. Default is 0.01.\n",
    "\n",
    "    Returns:\n",
    "    - A tuple containing the initialized model, MSE loss function, KL loss function, KL weight, and optimizer.\n",
    "    \"\"\"\n",
    "\n",
    "    model = DualOutputBNN(no_of_neurones, dropout_prob).to(device)\n",
    "\n",
    "    mse_loss = nn.MSELoss().to(device)\n",
    "    kl_loss = bnn.BKLLoss(reduction='mean', last_layer_only=False).to(device)\n",
    "    kl_weight = 0.01  # This could also be parameterized if needed\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    return model, mse_loss, kl_loss, kl_weight, optimizer\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
